{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 12\n",
    "plt.rcParams['image.cmap'] = 'jet'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.markersize'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy_scores(train_labels, test_labels, predictions_train_model, predictions_test_model):\n",
    "    acc_train = accuracy_score(train_labels, predictions_train_model)\n",
    "    acc_test = accuracy_score(test_labels, predictions_test_model)\n",
    "    print('Training set accuracy:   {:.3f}'.format(acc_train))\n",
    "    print('Test set accuracy:       {:.3f}'.format(acc_test))\n",
    "\n",
    "def print_stats(labels, predictions, title):\n",
    "    meas = precision_recall_fscore_support(labels, predictions, average=None, zero_division= np.nan)\n",
    "    print(title)\n",
    "    for i in range(2):\n",
    "        print('Class {0:d}: precision={1:5.3f}, recall={2:5.3f}, f-measure={3:5.3f}'.format(i, meas[0][i], meas[1][i], meas[2][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"pneumonia_images.npy\")\n",
    "y = (np.load(\"pneumonia_labels.npy\")).ravel()\n",
    "\n",
    "if (len(X) != len(y)):\n",
    "    raise ValueError(\"Numbers of images and labels do not match\")\n",
    "\n",
    "print(f\"The dataset is composed by {X.shape[0]} images {X.shape[1]}x{X.shape[2]}\")\n",
    "\n",
    "bin_count = np.bincount(y)\n",
    "if len(bin_count) != 2:\n",
    "    raise ValueError(\"Labels must be 0 or 1\")\n",
    "\n",
    "print(\"Negative examples: \", bin_count[0])\n",
    "print(\"Positive examples: \", bin_count[1])\n",
    "\n",
    "if bin_count[0] != bin_count[1]:\n",
    "    print(\"Imbalanced Dataset\")\n",
    "else:\n",
    "    print(\"Balanced Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 3\n",
    "n_cols = 7\n",
    "titles = [\"Negative\", \"Positive\"]\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(titles[y[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_histogram(image, color_space, channels=(0,1,2), bins=(8, 8, 8), range=(0, 256, 0, 256, 0, 256)):\n",
    "    if color_space is None:\n",
    "        cvt_img = image\n",
    "    else:\n",
    "        cvt_img = cv2.cvtColor(image, color_space)\n",
    "    hist = cv2.calcHist([cvt_img], channels, None, bins, range)\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "def get_histograms(dataset, color_space, channels, bins, channels_range):\n",
    "    histograms = []\n",
    "    for x in dataset:\n",
    "            hist = extract_histogram(x, color_space, channels, bins, channels_range)\n",
    "            histograms.append(hist)\n",
    "    return histograms\n",
    "\n",
    "def ranges(N, nb):\n",
    "    step = N / nb\n",
    "    return [\"{},{}\".format(round(step*i), round(step*(i+1))) for i in range(nb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist8bins = extract_histogram(X[5], None, (0,), (8,), (0, 256))\n",
    "hist16bins = extract_histogram(X[5], None, (0,), (16,), (0, 256))\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "axs[0].bar(ranges(255, 8), hist8bins)\n",
    "axs[1].bar(ranges(255, 16), hist16bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist8bins = extract_histogram(X[0], None, (0,), (8,), (0, 256))\n",
    "hist16bins = extract_histogram(X[0], None, (0,), (16,), (0, 256))\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "axs[0].bar(ranges(255, 8), hist8bins, color=\"red\")\n",
    "axs[1].bar(ranges(255, 16), hist16bins, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_8 = np.array(get_histograms(X, None, (0,), (8,), (0, 256)))\n",
    "bins_16 = np.array(get_histograms(X, None, (0,), (16,), (0, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistic_regression(hp):\n",
    "    model = LogisticRegression(\n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        C=hp.Float(\"C\", min_value=10e-6, max_value=0.1, step=10, sampling=\"log\"),\n",
    "        solver=hp.Choice(\"solver\", [\"liblinear\", \"saga\"]),\n",
    "        penalty= hp.Choice(\"penalty\", [\"l1\", \"l2\"]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.GridSearchOracle(objective=kt.Objective('score', 'max')),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    hypermodel= build_logistic_regression,\n",
    "    cv=StratifiedKFold(5),\n",
    "    project_name='tuners/log_reg_hist_8bins')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bins_8, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\nBest C: \", best_hps.get(\"C\"))\n",
    "print(\"\\nBest solver: \", best_hps.get(\"solver\"))\n",
    "print(\"\\nBest penalty: \", best_hps.get(\"penalty\"))\n",
    "\n",
    "print()\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "print_accuracy_scores(y_train, y_test, predictions_train, predictions_test)\n",
    "print_stats(y_train, predictions_train, \"Training set\")\n",
    "print_stats(y_test, predictions_test, \"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.GridSearchOracle(objective=kt.Objective('score', 'max')),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    hypermodel= build_logistic_regression,\n",
    "    cv=StratifiedKFold(5),\n",
    "    project_name='tuners/log_reg_hist_16bins')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bins_16, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\nBest C: \", best_hps.get(\"C\"))\n",
    "print(\"\\nBest solver: \", best_hps.get(\"solver\"))\n",
    "print(\"\\nBest penalty: \", best_hps.get(\"penalty\"))\n",
    "\n",
    "print()\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "print_accuracy_scores(y_train, y_test, predictions_train, predictions_test)\n",
    "print_stats(y_train, predictions_train, \"Training set\")\n",
    "print_stats(y_test, predictions_test, \"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_forest(hp):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=hp.Choice(\"n_estimators\", [50, 100, 250]),\n",
    "        criterion=hp.Choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        max_depth=hp.Choice(\"max_depth\", [1, 5, 10]),\n",
    "        max_features=hp.Choice(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "        n_jobs=-1, \n",
    "        random_state=42)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.GridSearchOracle(objective=kt.Objective('score', 'max')),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    hypermodel= build_random_forest,\n",
    "    cv=StratifiedKFold(5),\n",
    "    overwrite=False,\n",
    "    project_name='tuners/random_forest_hist_8bins')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bins_8, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best n_estimators:       \", best_hps.get(\"n_estimators\"))\n",
    "print(\"Best criterion:          \", best_hps.get(\"criterion\"))\n",
    "print(\"Best max_depth:          \", best_hps.get(\"max_depth\"))\n",
    "print(\"Best max_features:       \", best_hps.get(\"max_features\"))\n",
    "\n",
    "print()\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)  \n",
    "\n",
    "print_accuracy_scores(y_train, y_test, predictions_train, predictions_test)\n",
    "print_stats(y_train, predictions_train, \"Training set\")\n",
    "print_stats(y_test, predictions_test, \"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.GridSearchOracle(objective=kt.Objective('score', 'max')),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    hypermodel= build_random_forest,\n",
    "    cv=StratifiedKFold(5),\n",
    "    project_name='tuners/random_forest_hist_16bins')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bins_16, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best n_estimators:       \", best_hps.get(\"n_estimators\"))\n",
    "print(\"Best criterion:          \", best_hps.get(\"criterion\"))\n",
    "print(\"Best max_depth:          \", best_hps.get(\"max_depth\"))\n",
    "print(\"Best max_features:       \", best_hps.get(\"max_features\"))\n",
    "\n",
    "print()\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "print_accuracy_scores(y_train, y_test, predictions_train, predictions_test)\n",
    "print_stats(y_train, predictions_train, \"Training set\")\n",
    "print_stats(y_test, predictions_test, \"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adaboost_trees(hp):\n",
    "    model = AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(\n",
    "            criterion=hp.Choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            max_depth=hp.Choice(\"max_depth\", [1, 5, 10, 15]),\n",
    "            random_state=42),\n",
    "        n_estimators=hp.Choice(\"n_estimators\", [50, 100, 250, 500]),\n",
    "        learning_rate=hp.Choice(\"learning_rate\", [0.001, 0.01, 0.1, 1.0, 10.0]),\n",
    "        algorithm=\"SAMME\",\n",
    "        random_state=42)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.GridSearchOracle(objective=kt.Objective('score', 'max')),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    hypermodel= build_adaboost_trees,\n",
    "    cv=StratifiedKFold(5),\n",
    "    project_name='tuners/adaboost_hist_8bins')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bins_8, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best criterion:          \", best_hps.get(\"criterion\"))\n",
    "print(\"Best max_depth:          \", best_hps.get(\"max_depth\"))\n",
    "print(\"Best n_estimators:       \", best_hps.get(\"n_estimators\"))\n",
    "print(\"Best learning_rate:      \", best_hps.get(\"learning_rate\"))\n",
    "\n",
    "print()\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "print_accuracy_scores(y_train, y_test, predictions_train, predictions_test)\n",
    "print_stats(y_train, predictions_train, \"Training set\")\n",
    "print_stats(y_test, predictions_test, \"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.GridSearchOracle(objective=kt.Objective('score', 'max')),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    hypermodel= build_adaboost_trees,\n",
    "    cv=StratifiedKFold(5),\n",
    "    project_name='tuners/adaboost_hist_16bins')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bins_16, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best criterion:          \", best_hps.get(\"criterion\"))\n",
    "print(\"Best max_depth:          \", best_hps.get(\"max_depth\"))\n",
    "print(\"Best n_estimators:       \", best_hps.get(\"n_estimators\"))\n",
    "print(\"Best learning_rate:      \", best_hps.get(\"learning_rate\"))\n",
    "\n",
    "print()\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "print_accuracy_scores(y_train, y_test, predictions_train, predictions_test)\n",
    "print_stats(y_train, predictions_train, \"Training set\")\n",
    "print_stats(y_test, predictions_test, \"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knn(hp):\n",
    "    model = KNeighborsClassifier(\n",
    "        n_neighbors=hp.Int(\"n_neighbors\", min_value=1, max_value=10, step=1),\n",
    "        weights=hp.Choice(\"weights\", [\"uniform\", \"distance\"]),\n",
    "        algorithm=hp.Choice(\"algorithm\", [\"ball_tree\", \"kd_tree\"]),\n",
    "        p=hp.Float(\"p\", min_value=1, max_value=2, step=1),\n",
    "        n_jobs=-1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.GridSearchOracle(objective=kt.Objective('score', 'max')),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    hypermodel= build_knn,\n",
    "    cv=StratifiedKFold(5),\n",
    "    project_name='tuners/knn_hist_8bins')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bins_8, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best n_neighbors:    \", best_hps.get(\"n_neighbors\"))\n",
    "print(\"Best weights:        \", best_hps.get(\"weights\"))\n",
    "print(\"Best algorithm:      \", best_hps.get(\"algorithm\"))\n",
    "print(\"Best p:              \", best_hps.get(\"p\"))\n",
    "\n",
    "print()\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "print_accuracy_scores(y_train, y_test, predictions_train, predictions_test)\n",
    "print_stats(y_train, predictions_train, \"Training set\")\n",
    "print_stats(y_test, predictions_test, \"Test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.GridSearchOracle(objective=kt.Objective('score', 'max')),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    hypermodel= build_knn,\n",
    "    cv=StratifiedKFold(5),\n",
    "    project_name='tuners/knn_hist_16bins')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bins_16, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best n_neighbors:    \", best_hps.get(\"n_neighbors\"))\n",
    "print(\"Best weights:        \", best_hps.get(\"weights\"))\n",
    "print(\"Best algorithm:      \", best_hps.get(\"algorithm\"))\n",
    "print(\"Best p:              \", best_hps.get(\"p\"))\n",
    "\n",
    "print()\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = model.predict(X_test)\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "print_accuracy_scores(y_train, y_test, predictions_train, predictions_test)\n",
    "print_stats(y_train, predictions_train, \"Training set\")\n",
    "print_stats(y_test, predictions_test, \"Test set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
